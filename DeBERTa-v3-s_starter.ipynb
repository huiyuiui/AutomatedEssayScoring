{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBERTa-v3-SMALL Regression Starter\n",
    "This notebook is a fork from Yuto_H's great notebook [here][1]. If you like my notebook, remember to upvote Yuto's notebook too. In this notebook we add the following modifications which are explained in my discussion post [here][3]:\n",
    "* Change model to `DeBERTa-v3-small` for fast experiments (Note that `xsmall` works well too)\n",
    "* Increase token `max_length to 1024` (instead of 512 to include all essay text)\n",
    "* Use total `train batch size = 8`, valid batch size 16 (Note `batch per gpu = 4` and we have 2xT4 GPU)\n",
    "* Train `4 epochs linear` with start `LR = 1e-5` and `no warmup`\n",
    "* Remove seed everything (I like randomness)\n",
    "* Add `QWK metric for regression`\n",
    "* Add `new tokens` to tokenizer because DeBERTa removes \"new paragraph\" and \"double space\" from essay\n",
    "* `Remove dropout` for regression\n",
    "* Save `full OOF` predictions\n",
    "* Add `test inference` and `LB submit`\n",
    "* Achieves surprising `CV = 0.822` WOW! and LB = ??? (submitting now, let's see what LB is...)\n",
    "\n",
    "For training, this notebook averages 1 hour per fold which is 15 minutes per epoch training on 2xT4 Kaggle GPU. (Training is done in version 1. And inference and submit to LB is done in version 2).\n",
    "\n",
    "# Version Notes\n",
    "In version 1, we finetune a new DeBERTa-v3-SMALL and save it to the Kaggle dataset [here][4]. Therefore if you want to see training epoch details, view notebook version 1. This took 6 hours using Kaggle's 2xT4 GPU.\n",
    "\n",
    "In notebook version 2, we load the saved fold models and infer test data and submit to LB. Version 2 runs quickly because it is only inference. It will run in either 6 minutes or 1 minute depending on whether we infer OOF and compute CV score again.\n",
    "\n",
    "If we want version 2 inference to run more quickly, we can set `COMPUTE_CV = False` below, then we will not use 5 minutes to predict OOF and compute CV score. Instead we will only infer test data.\n",
    "\n",
    "[1]: https://www.kaggle.com/code/hashidoyuto/deberta-baseline-aes2-0-train\n",
    "[2]: https://www.kaggle.com/code/hashidoyuto/deberta-v3-base-aes2-0-infer\n",
    "[3]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832\n",
    "[4]: https://www.kaggle.com/datasets/cdeotte/deberta-v3-small-finetuned-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Data Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d cdeotte/deberta-v3-small-finetuned-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip deberta-v3-small-finetuned-v1.zip -d ./kaggle/input/deberta-v3-small-finetuned-v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d verracodeguacas/huggingfacedebertav3variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip huggingfacedebertav3variants.zip -d ./kaggle/input/huggingfacedebertav3variants/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download nbroad/persaude-corpus-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip persaude-corpus-2.zip -d ./kaggle/input/persaude-corpus-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Config\n",
    "Import libraries and define configuration parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #TODO: Kaggle using 2 T4 GPU, so remember to modify it to 0,1\n",
    "\n",
    "# True USES REGRESSION, False USES CLASSIFICATION\n",
    "USE_REGRESSION = True\n",
    "\n",
    "# VERSION NUMBER FOR NAMING OF SAVED MODELS\n",
    "VER=1\n",
    "\n",
    "# IF \"LOAD_FROM\" IS None, THEN WE TRAIN NEW MODELS\n",
    "# LOAD_FROM = \"./kaggle/input/deberta-v3-small-finetuned-v1/\"\n",
    "# LOAD_FROM = None\n",
    "LOAD_FROM = \"./kaggle/input/deberta-small-two-stage-v1/\" # TODO: when submit to kaggle, activate this line\n",
    "\n",
    "# WHEN TRAINING NEW MODELS SET COMPUTE_CV = True\n",
    "# WHEN LOADING MODELS, WE CAN CHOOSE True or False\n",
    "COMPUTE_CV = False #TODO: When submit to kaggle, modify it to False\n",
    "\n",
    "# WHEN TWO-STAGE TRAINING, SET PSEUDO_LABEL = True AND RETRAIN = True\n",
    "PSEUDO_LABEL= False # TODO: when submit to kaggle, modify it to False\n",
    "RETRAIN = False  # TODO: when submit to kaggle, modify it to False\n",
    "INFERENCE = True #TODO: when submit to kaggle, modify it to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tokenizers import AddedToken\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATHS: # TODO: modify path (.)\n",
    "    train_path = './kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
    "    test_path = './kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
    "    sub_path = './kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv'\n",
    "    model_path = \"./kaggle/input/huggingfacedebertav3variants/deberta-v3-small\"\n",
    "    # model_path = \"./kaggle/input/huggingfacedebertav3variants/deberta-v3-large\"\n",
    "    persuade_path = './kaggle/input/persaude-corpus-2/persuade_2.0_human_scores_demo_id_github.csv'\n",
    "    finetune_path = './kaggle/input/deberta-small-two-stage-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_splits = 5 # 5 or 7 are the best\n",
    "    seed = 42 \n",
    "    max_length = 1024\n",
    "    lr_phase1 = 1e-5 # 1e-5 is the best\n",
    "    lr_phase2 = 1e-5\n",
    "    train_batch_size = 8 # total 8: 4 * 2\n",
    "    eval_batch_size = 16 # total 16: 8 * 2\n",
    "    train_phase1_epochs = 4 # 4 is the best\n",
    "    train_phase2_epochs = 2\n",
    "    weight_decay = 0.01\n",
    "    warmup_ratio = 0.0\n",
    "    num_labels = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tokenization\n",
    "We use `max_length = 1024` to avoid truncating majority of essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenize(object):\n",
    "    def __init__(self, train, valid, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        \n",
    "    def get_dataset(self, df):\n",
    "        ds = Dataset.from_dict({\n",
    "                'essay_id': [e for e in df['essay_id']],\n",
    "                'full_text': [ft for ft in df['full_text']],\n",
    "                'label': [s for s in df['label']],\n",
    "            })\n",
    "        return ds\n",
    "        \n",
    "    def tokenize_function(self, example):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            example['full_text'], truncation=True, max_length=CFG.max_length\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "    \n",
    "    def __call__(self):\n",
    "        train_ds = self.get_dataset(self.train)\n",
    "        valid_ds = self.get_dataset(self.valid)\n",
    "        \n",
    "        tokenized_train = train_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        tokenized_valid = valid_ds.map(\n",
    "            self.tokenize_function, batched=True\n",
    "        )\n",
    "        \n",
    "        return tokenized_train, tokenized_valid, self.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "Below we provide compute metric function for both regression and classification. In this notebook we will use regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_regression(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.clip(0,5).round(0), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_classification(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights='quadratic')\n",
    "    results = {\n",
    "        'qwk': qwk\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Set Fold\n",
    "For our label, we will use `label = score - 1`. Then the labels will range from 0 to 5. For regression, we convert the label to `float32`. For classification, we would convert to `int32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin data length: 17307\n",
      "Persuade data length(intersection): 12871\n",
      "Non-persuade data length(difference): 4436\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(PATHS.train_path)\n",
    "data['label'] = data['score'].apply(lambda x: x-1)\n",
    "if USE_REGRESSION: data[\"label\"] = data[\"label\"].astype('float32') \n",
    "else: data[\"label\"] = data[\"label\"].astype('int32')\n",
    "print(\"Origin data length:\", len(data))\n",
    "\n",
    "persuade = pd.read_csv(PATHS.persuade_path)\n",
    "intersection = pd.merge(data, persuade, on=\"full_text\", how=\"inner\")[[\"essay_id\", \"full_text\", \"score\", \"label\", \"prompt_name\"]].reset_index(drop=True)\n",
    "difference = data[~data[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "print(\"Persuade data length(intersection):\", len(intersection))\n",
    "print(\"Non-persuade data length(difference):\", len(difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use persuade data as phase 1 training dataset, and use non-persuade data as phase 2 training dtaset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>score_and_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>3-Car-free cities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>3-Does the electoral college work?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030e86</td>\n",
       "      <td>If I were to choose between keeping the electo...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>4-Does the electoral college work?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033bf4</td>\n",
       "      <td>What is the Seagoing Cowboys progam?\\n\\nIt was...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>3-\"A Cowboy Who Rode the Waves\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036253</td>\n",
       "      <td>The challenge of exploring Venus\\n\\nThis stori...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>2-Exploring Venus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3    2.0   \n",
       "1  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "2  0030e86  If I were to choose between keeping the electo...      4    3.0   \n",
       "3  0033bf4  What is the Seagoing Cowboys progam?\\n\\nIt was...      3    2.0   \n",
       "4  0036253  The challenge of exploring Venus\\n\\nThis stori...      2    1.0   \n",
       "\n",
       "                        prompt_name                    score_and_prompt  \n",
       "0                   Car-free cities                   3-Car-free cities  \n",
       "1  Does the electoral college work?  3-Does the electoral college work?  \n",
       "2  Does the electoral college work?  4-Does the electoral college work?  \n",
       "3     \"A Cowboy Who Rode the Waves\"     3-\"A Cowboy Who Rode the Waves\"  \n",
       "4                   Exploring Venus                   2-Exploring Venus  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection[\"score_and_prompt\"] = intersection[\"score\"].astype(str) + \"-\" + intersection[\"prompt_name\"]\n",
    "\n",
    "intersection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>score_and_prompt</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>3-Car-free cities</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>3-Does the electoral college work?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030e86</td>\n",
       "      <td>If I were to choose between keeping the electo...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>4-Does the electoral college work?</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033bf4</td>\n",
       "      <td>What is the Seagoing Cowboys progam?\\n\\nIt was...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>3-\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036253</td>\n",
       "      <td>The challenge of exploring Venus\\n\\nThis stori...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>2-Exploring Venus</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3    2.0   \n",
       "1  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "2  0030e86  If I were to choose between keeping the electo...      4    3.0   \n",
       "3  0033bf4  What is the Seagoing Cowboys progam?\\n\\nIt was...      3    2.0   \n",
       "4  0036253  The challenge of exploring Venus\\n\\nThis stori...      2    1.0   \n",
       "\n",
       "                        prompt_name                    score_and_prompt  fold  \n",
       "0                   Car-free cities                   3-Car-free cities   1.0  \n",
       "1  Does the electoral college work?  3-Does the electoral college work?   0.0  \n",
       "2  Does the electoral college work?  4-Does the electoral college work?   3.0  \n",
       "3     \"A Cowboy Who Rode the Waves\"     3-\"A Cowboy Who Rode the Waves\"   3.0  \n",
       "4                   Exploring Venus                   2-Exploring Venus   3.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf_42 = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "# phase 1\n",
    "if PSEUDO_LABEL:\n",
    "    persuade_data = pd.read_csv('./kaggle/input/pseudo_labeling.csv')\n",
    "else:\n",
    "    persuade_data = intersection.copy(deep=True)\n",
    "    for i, (_, val_index) in enumerate(skf_42.split(persuade_data, persuade_data[\"score_and_prompt\"])):\n",
    "        persuade_data.loc[val_index, \"fold\"] = i\n",
    "        \n",
    "persuade_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033037</td>\n",
       "      <td>The posibilty of a face reconizing computer wo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0065bd6</td>\n",
       "      <td>Driverless cars should not exsist it can cause...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000fe60  I am a scientist at NASA that is discussing th...      3    2.0   \n",
       "1  001ab80  People always wish they had the same technolog...      4    3.0   \n",
       "2  001bdc0  We all heard about Venus, the planet without a...      4    3.0   \n",
       "3  0033037  The posibilty of a face reconizing computer wo...      2    1.0   \n",
       "4  0065bd6  Driverless cars should not exsist it can cause...      3    2.0   \n",
       "\n",
       "   fold  \n",
       "0   1.0  \n",
       "1   3.0  \n",
       "2   2.0  \n",
       "3   1.0  \n",
       "4   2.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phase 2\n",
    "skf_6 = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "non_persuade_data = difference.copy(deep=True)\n",
    "for i, (_, val_index) in enumerate(skf_6.split(non_persuade_data, non_persuade_data[\"score\"])):\n",
    "    non_persuade_data.loc[val_index, \"fold\"] = i\n",
    "non_persuade_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Args\n",
    "We use `fp16=True` which uses mixed precision and uses less GPU VRAM and makes training faster. We use `per_device_train_batch_size = (8 / number of gpus)` because we want total train batch size to be 8. With Kaggle T4, we have 2xT4 GPUs and use `per_device_train_batch_size = 4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_phase1 = TrainingArguments(\n",
    "    output_dir=f'output_v{VER}_phase1',\n",
    "    fp16=True,\n",
    "    learning_rate=CFG.lr_phase1,\n",
    "    per_device_train_batch_size=CFG.train_batch_size,\n",
    "    per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "    num_train_epochs=CFG.train_phase1_epochs,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    evaluation_strategy='epoch',\n",
    "    metric_for_best_model='qwk',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "    optim='adamw_torch',\n",
    "    logging_first_step=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_phase2 = TrainingArguments(\n",
    "    output_dir=f'output_v{VER}_phase2',\n",
    "    fp16=True,\n",
    "    learning_rate=CFG.lr_phase2,\n",
    "    per_device_train_batch_size=CFG.train_batch_size,\n",
    "    per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "    num_train_epochs=CFG.train_phase2_epochs,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    evaluation_strategy='epoch',\n",
    "    metric_for_best_model='qwk',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    lr_scheduler_type='linear', # \"cosine\" or \"linear\" or \"constant\"\n",
    "    optim='adamw_torch',\n",
    "    logging_first_step=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Fold Training\n",
    "We add new tokens for (\"\\n\") new paragraph and (\" \"*2) double space because the default DeBERTa tokenizer removes these but these are helpful for scoring essays. We remove dropout from our model because this does not work well when using regression. Read discussion [here][1]\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 1\n",
    "if COMPUTE_CV:\n",
    "    for fold in range(len(persuade_data['fold'].unique())):\n",
    "\n",
    "        # GET TRAIN AND VALID DATA\n",
    "        train = persuade_data[persuade_data['fold'] != fold]\n",
    "        valid = persuade_data[persuade_data['fold'] == fold].copy()\n",
    "\n",
    "        # PSEUDO-LABEL\n",
    "        if PSEUDO_LABEL:\n",
    "            print(\"Using Pseudo-label\")\n",
    "            train['label'] = train['pseudo_label'].astype('float32')\n",
    "\n",
    "        # ADD NEW TOKENS for (\"\\n\") new paragraph and (\" \"*2) double space \n",
    "        if RETRAIN:\n",
    "            tokenizer_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "            tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)    \n",
    "        else:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(PATHS.model_path)\n",
    "            tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "            tokenizer.add_tokens([AddedToken(\" \"*2, normalized=False)])\n",
    "\n",
    "        tokenize = Tokenize(train, valid, tokenizer)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        if RETRAIN:\n",
    "            config_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "        else:\n",
    "            # REMOVE DROPOUT FROM REGRESSION\n",
    "            config = AutoConfig.from_pretrained(PATHS.model_path)\n",
    "            if USE_REGRESSION:\n",
    "                config.attention_probs_dropout_prob = 0.0 \n",
    "                config.hidden_dropout_prob = 0.0 \n",
    "                config.num_labels = 1 \n",
    "            else: config.num_labels = CFG.num_labels \n",
    "\n",
    "        if LOAD_FROM and INFERENCE:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(LOAD_FROM + f'deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "        elif RETRAIN:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(config_path)\n",
    "        else:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(PATHS.model_path, config=config)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        # TRAIN WITH TRAINER\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        if USE_REGRESSION: compute_metrics = compute_metrics_for_regression\n",
    "        else: compute_metrics = compute_metrics_for_classification\n",
    "        trainer_phase1 = Trainer( \n",
    "            model=model,\n",
    "            args=training_args_phase1,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        if LOAD_FROM is None or RETRAIN is True:\n",
    "            print(f\"Training fold {fold}:\")\n",
    "            trainer_phase1.train()\n",
    "        \n",
    "        # PLOT CONFUSION MATRIX\n",
    "        y_true = valid['score'].values\n",
    "        predictions0 = trainer_phase1.predict(tokenized_valid).predictions\n",
    "        if USE_REGRESSION: predictions = predictions0.round(0) + 1\n",
    "        else: predictions = predictions0.argmax(axis=1) + 1 \n",
    "        cm = confusion_matrix(y_true, predictions, labels=[x for x in range(1,7)])\n",
    "        draw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=[x for x in range(1,7)])\n",
    "        draw_cm.plot()\n",
    "        plt.show()\n",
    "\n",
    "        # SAVE FOLD MODEL AND TOKENIZER\n",
    "        if LOAD_FROM is None:\n",
    "            trainer_phase1.save_model(PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}_phase1')\n",
    "            tokenizer.save_pretrained(PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}_phase1')\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        if USE_REGRESSION: \n",
    "            valid['pred'] = predictions0 + 1 \n",
    "        else:\n",
    "            COLS = [f'p{x}' for x in range(CFG.num_labels)] \n",
    "            valid[COLS] = predictions0 \n",
    "        valid.to_csv(f'phase1_valid_df_fold_{fold}_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 2\n",
    "if COMPUTE_CV:\n",
    "    for fold in range(len(non_persuade_data['fold'].unique())):\n",
    "\n",
    "        # GET TRAIN AND VALID DATA\n",
    "        train = non_persuade_data[non_persuade_data['fold'] != fold]\n",
    "        valid = non_persuade_data[non_persuade_data['fold'] == fold].copy()\n",
    "\n",
    "        # ADD NEW TOKENS for (\"\\n\") new paragraph and (\" \"*2) double space \n",
    "        tokenizer_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}_phase1'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        tokenize = Tokenize(train, valid, tokenizer)\n",
    "        tokenized_train, tokenized_valid, _ = tokenize()\n",
    "\n",
    "        # LOAD CONFIG AND MODEL FROM PHASE 1\n",
    "        config_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}_phase1'\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(config_path)\n",
    "\n",
    "        # TRAIN WITH TRAINER\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        if USE_REGRESSION: compute_metrics = compute_metrics_for_regression\n",
    "        else: compute_metrics = compute_metrics_for_classification\n",
    "        trainer_phase2 = Trainer( \n",
    "            model=model,\n",
    "            args=training_args_phase2,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_valid,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        if LOAD_FROM is None:\n",
    "            trainer_phase2.train()\n",
    "        \n",
    "        # PLOT CONFUSION MATRIX\n",
    "        y_true = valid['score'].values\n",
    "        predictions0 = trainer_phase2.predict(tokenized_valid).predictions\n",
    "        if USE_REGRESSION: predictions = predictions0.round(0) + 1\n",
    "        else: predictions = predictions0.argmax(axis=1) + 1 \n",
    "        cm = confusion_matrix(y_true, predictions, labels=[x for x in range(1,7)])\n",
    "        draw_cm = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=[x for x in range(1,7)])\n",
    "        draw_cm.plot()\n",
    "        plt.show()\n",
    "\n",
    "        # SAVE FOLD MODEL AND TOKENIZER\n",
    "        if LOAD_FROM is None:\n",
    "            trainer_phase2.save_model(PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "            tokenizer.save_pretrained(PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        if USE_REGRESSION: \n",
    "            valid['pred'] = predictions0 + 1 \n",
    "        else:\n",
    "            COLS = [f'p{x}' for x in range(CFG.num_labels)] \n",
    "            valid[COLS] = predictions0 \n",
    "        valid.to_csv(f'phase2_valid_df_fold_{fold}_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Pseudo-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pseudo-label creation function\n",
    "def create_pseudo_labels(dataset):\n",
    "    predictions_list = []\n",
    "    \n",
    "    for fold in range(len(dataset['fold'].unique())):\n",
    "        \n",
    "        # Tokenize data\n",
    "        tokenizer_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        tokenize = Tokenize(dataset, dataset, tokenizer)\n",
    "        tokenized_dataset, _, _ = tokenize()\n",
    "        \n",
    "        # Load fold model\n",
    "        config_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(config_path)\n",
    "\n",
    "        # make prediction\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=TrainingArguments(\n",
    "                per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "                output_dir='./output/pseudo_labeling',\n",
    "                report_to='none'\n",
    "            ),\n",
    "            data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "        predictions = trainer.predict(tokenized_dataset).predictions\n",
    "        \n",
    "        if USE_REGRESSION:\n",
    "            predicted_labels = predictions.round(0) + 1\n",
    "        else:\n",
    "            predicted_labels = predictions.argmax(axis=1) + 1\n",
    "            \n",
    "        predictions_list.append(predicted_labels)\n",
    "        print(f\"Fold {fold}: Predictions shape = {predicted_labels.shape}\")\n",
    "    \n",
    "    avg_predictions = sum(predictions_list) / len(predictions_list)\n",
    "\n",
    "    # Create pseudo-label using weighted average with original score\n",
    "    weight_label = 8\n",
    "    weight_pred = 2\n",
    "    dataset['pseudo_label'] = (weight_label * dataset['score'] + weight_pred * avg_predictions) / (weight_label + weight_pred)\n",
    "    \n",
    "    # save pseudo-labels dataset\n",
    "    dataset.to_csv('./kaggle/input/pseudo_labeling.csv', index=False)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INFERENCE:\n",
    "    persuade_data = create_pseudo_labels(persuade_data)\n",
    "    PSEUDO_LABEL = True\n",
    "    RETRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>score_and_prompt</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>3-Car-free cities</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>3-Does the electoral college work?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030e86</td>\n",
       "      <td>If I were to choose between keeping the electo...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>4-Does the electoral college work?</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033bf4</td>\n",
       "      <td>What is the Seagoing Cowboys progam?\\n\\nIt was...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>3-\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036253</td>\n",
       "      <td>The challenge of exploring Venus\\n\\nThis stori...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exploring Venus</td>\n",
       "      <td>2-Exploring Venus</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3    2.0   \n",
       "1  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "2  0030e86  If I were to choose between keeping the electo...      4    3.0   \n",
       "3  0033bf4  What is the Seagoing Cowboys progam?\\n\\nIt was...      3    2.0   \n",
       "4  0036253  The challenge of exploring Venus\\n\\nThis stori...      2    1.0   \n",
       "\n",
       "                        prompt_name                    score_and_prompt  fold  \n",
       "0                   Car-free cities                   3-Car-free cities   1.0  \n",
       "1  Does the electoral college work?  3-Does the electoral college work?   0.0  \n",
       "2  Does the electoral college work?  4-Does the electoral college work?   3.0  \n",
       "3     \"A Cowboy Who Rode the Waves\"     3-\"A Cowboy Who Rode the Waves\"   3.0  \n",
       "4                   Exploring Venus                   2-Exploring Venus   3.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuade_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    # Initialize a list to store all folds' results\n",
    "    all_folds = []\n",
    "\n",
    "    # Read Phase 1 predictions\n",
    "    for fold in range(CFG.n_splits):\n",
    "        phase1_path = f'phase1_valid_df_fold_{fold}_v{VER}.csv'\n",
    "        phase1_df = pd.read_csv(phase1_path)\n",
    "        all_folds.append(phase1_df)\n",
    "\n",
    "    # Read Phase 2 predictions\n",
    "    for fold in range(CFG.n_splits):\n",
    "        phase2_path = f'phase2_valid_df_fold_{fold}_v{VER}.csv'\n",
    "        phase2_df = pd.read_csv(phase2_path)\n",
    "        all_folds.append(phase2_df)\n",
    "\n",
    "    # Concatenate all folds\n",
    "    overall_df = pd.concat(all_folds, axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Save the overall predictions to a CSV file (optional)\n",
    "    overall_df.to_csv(f'overall_valid_df_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>score_and_prompt</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>3-Does the electoral college work?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.569336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005a72e</td>\n",
       "      <td>I agree that driverless cars are a developing ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Driverless cars</td>\n",
       "      <td>4-Driverless cars</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.365234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006d0e1</td>\n",
       "      <td>Have you ever seen Europe? What about China, o...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>4-\"A Cowboy Who Rode the Waves\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.173828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00aa6de</td>\n",
       "      <td>This system could be very benificial in classr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Facial action coding system</td>\n",
       "      <td>2-Facial action coding system</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.166016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b2fe2</td>\n",
       "      <td>I think the idea of \"driverless\"'cars might no...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Driverless cars</td>\n",
       "      <td>4-Driverless cars</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.582031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "1  005a72e  I agree that driverless cars are a developing ...      4    3.0   \n",
       "2  006d0e1  Have you ever seen Europe? What about China, o...      4    3.0   \n",
       "3  00aa6de  This system could be very benificial in classr...      2    1.0   \n",
       "4  00b2fe2  I think the idea of \"driverless\"'cars might no...      4    3.0   \n",
       "\n",
       "                        prompt_name                    score_and_prompt  fold  \\\n",
       "0  Does the electoral college work?  3-Does the electoral college work?   0.0   \n",
       "1                   Driverless cars                   4-Driverless cars   0.0   \n",
       "2     \"A Cowboy Who Rode the Waves\"     4-\"A Cowboy Who Rode the Waves\"   0.0   \n",
       "3       Facial action coding system       2-Facial action coding system   0.0   \n",
       "4                   Driverless cars                   4-Driverless cars   0.0   \n",
       "\n",
       "       pred  \n",
       "0  2.569336  \n",
       "1  4.365234  \n",
       "2  4.173828  \n",
       "3  2.166016  \n",
       "4  3.582031  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    # Calculate Overall CV (QWK)\n",
    "    if USE_REGRESSION:\n",
    "        overall_score = cohen_kappa_score(\n",
    "            overall_df['score'].values,\n",
    "            overall_df['pred'].values.clip(1, 6).round(0),\n",
    "            weights='quadratic'\n",
    "        )\n",
    "    else:\n",
    "        overall_score = cohen_kappa_score(\n",
    "            overall_df['score'].values,\n",
    "            overall_df.iloc[:, -CFG.num_labels:].values.argmax(axis=1) + 1,\n",
    "            weights='quadratic'\n",
    "        )\n",
    "\n",
    "    print(f'Overall QWK CV = {overall_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaRounder:\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "        self.labels = np.unique(y_true)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        thresholds = []\n",
    "        for i in range(len(self.labels) - 1):\n",
    "            low = max(thresholds) if i > 0 else min(self.labels)\n",
    "            high = max(self.labels)\n",
    "            t = trial.suggest_uniform(f't{i}', low, high)\n",
    "            thresholds.append(t)\n",
    "        try:\n",
    "            opt_y_pred = self.adjust(self.y_pred, thresholds)\n",
    "        except: return 0\n",
    "        return cohen_kappa_score(self.y_true, opt_y_pred, weights='quadratic')\n",
    "\n",
    "    def adjust(self, y_pred, thresholds):\n",
    "        opt_y_pred = pd.cut(y_pred,\n",
    "                            [-np.inf] + thresholds + [np.inf],\n",
    "                            labels=self.labels)\n",
    "        return opt_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(dataset):\n",
    "    predictions_list = []\n",
    "    \n",
    "    for fold in range(len(dataset['fold'].unique())):\n",
    "        \n",
    "        # Tokenize data\n",
    "        tokenizer_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        tokenize = Tokenize(dataset, dataset, tokenizer)\n",
    "        tokenized_dataset, _, _ = tokenize()\n",
    "        \n",
    "        # Load fold model\n",
    "        config_path = PATHS.finetune_path + f'/deberta-v3-small_AES2_fold_{fold}_v{VER}'\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(config_path)\n",
    "\n",
    "        # make prediction\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=TrainingArguments(\n",
    "                per_device_eval_batch_size=CFG.eval_batch_size,\n",
    "                output_dir='./output/pseudo_labeling',\n",
    "                report_to='none'\n",
    "            ),\n",
    "            data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "        predictions = trainer.predict(tokenized_dataset).predictions\n",
    "            \n",
    "        predictions_list.append(predictions)\n",
    "        print(f\"Fold {fold}: Predictions shape = {predictions.shape}\")\n",
    "    \n",
    "    avg_predictions = sum(predictions_list) / len(predictions_list)\n",
    "    dataset['avg_pred'] = avg_predictions\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3    2.0   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3    2.0   \n",
       "2  001ab80  People always wish they had the same technolog...      4    3.0   \n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4    3.0   \n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "\n",
       "   fold  \n",
       "0   3.0  \n",
       "1   4.0  \n",
       "2   1.0  \n",
       "3   0.0  \n",
       "4   2.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (_, val_index) in enumerate(skf_6.split(data, data[\"score\"])):\n",
    "    data.loc[val_index, \"fold\"] = i\n",
    "        \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text  score  label  \\\n",
       "0  000d118  Many people have car where they live. The thin...      3    2.0   \n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3    2.0   \n",
       "2  001ab80  People always wish they had the same technolog...      4    3.0   \n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4    3.0   \n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3    2.0   \n",
       "\n",
       "   fold  \n",
       "0   3.0  \n",
       "1   4.0  \n",
       "2   1.0  \n",
       "3   0.0  \n",
       "4   2.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_dataset = data.copy()\n",
    "if not INFERENCE:\n",
    "    opt_dataset = predict_dataset(data)\n",
    "    \n",
    "opt_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not INFERENCE:\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING) \n",
    "    objective = OptunaRounder(opt_dataset['label'].values, opt_dataset['avg_pred'].values)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=0))\n",
    "    study.optimize(objective, timeout=200)\n",
    "    best_thresholds = sorted(study.best_params.values())\n",
    "    print(f'Optimized thresholds: {best_thresholds}')\n",
    "\n",
    "    preds_opt = objective.adjust(opt_dataset['avg_pred'].values, best_thresholds)\n",
    "    preds_opt = preds_opt.astype(int)\n",
    "\n",
    "    qwk = cohen_kappa_score(opt_dataset['label'], preds_opt, weights='quadratic')\n",
    "    f1 = f1_score(opt_dataset['label'], preds_opt, average='macro')\n",
    "    acc = accuracy_score(opt_dataset['label'], preds_opt)\n",
    "    print(\"QWK: %.5f\"%qwk, \"F1: %.5f\"%f1, \"Accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer Test Data\n",
    "We infer test data using Hugging Face trainer and load our saved best fold models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                          full_text\n",
       "0  000d118  Many people have car where they live. The thin...\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...\n",
       "2  001ab80  People always wish they had the same technolog..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(PATHS.test_path)\n",
    "print('Test shape:', test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 3/3 [00:00<00:00, 406.41 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 531.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 3/3 [00:00<00:00, 446.55 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 515.57 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 3/3 [00:00<00:00, 506.60 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 532.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 3/3 [00:00<00:00, 463.53 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 476.17 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 3/3 [00:00<00:00, 458.28 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 563.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_pred = []\n",
    "test['label'] = 0.0\n",
    "\n",
    "for fold in range(CFG.n_splits):\n",
    "    \n",
    "    # LOAD TOKENIZER\n",
    "    if LOAD_FROM:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(LOAD_FROM + f'deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(f'deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "    tokenize = Tokenize(test, test, tokenizer)\n",
    "    tokenized_test, _, _ = tokenize()\n",
    "\n",
    "    # LOAD MODEL\n",
    "    if LOAD_FROM:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(LOAD_FROM + f'deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "    else:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f'deberta-v3-small_AES2_fold_{fold}_v{VER}')\n",
    "    \n",
    "    # CREATE TRAINING ARGS FOR INFERENCE\n",
    "    inference_args = TrainingArguments(\n",
    "        per_device_eval_batch_size=CFG.eval_batch_size,  \n",
    "        fp16=True,                      \n",
    "        do_train=False,                 \n",
    "        do_eval=False,                  \n",
    "        logging_dir='./logs',          \n",
    "        report_to=\"none\",\n",
    "        output_dir='output_v1'                \n",
    "    )\n",
    "\n",
    "    # INFER WITH TRAINER\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainer = Trainer( \n",
    "        model=model,\n",
    "        args=inference_args,\n",
    "        train_dataset=tokenized_test,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # SAVE PREDICTIONS\n",
    "    predictions = trainer.predict(tokenized_test).predictions\n",
    "    all_pred.append( predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (3,)\n",
      "[1.800586  2.0132813 3.4617188]\n"
     ]
    }
   ],
   "source": [
    "preds = np.mean(all_pred, axis=0)\n",
    "print('Predictions shape:',preds.shape)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Best Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_opt_thresholds(predictions, thresholds):\n",
    "    labels = np.zeros_like(predictions, dtype=int)\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        labels += (predictions > threshold).astype(int)\n",
    "        \n",
    "    return labels + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 5]\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = [0.781520185283719, 1.6011450107222063, 2.5870851259767407, 3.205894677704853, 3.649166723300159]\n",
    "\n",
    "opt_pred = apply_opt_thresholds(preds, best_thresholds)\n",
    "print(opt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      3\n",
       "1  000fe60      3\n",
       "2  001ab80      5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(PATHS.sub_path)\n",
    "# if USE_REGRESSION: sub[\"score\"] = preds.clip(0,5).round(0)+1\n",
    "if USE_REGRESSION: sub['score'] = opt_pred\n",
    "else: sub[\"score\"] = preds.argmax(axis=1)+1\n",
    "sub.score = sub.score.astype('int32')\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "print('Submission shape:', sub.shape )\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
